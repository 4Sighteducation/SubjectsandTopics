# Hybrid Scraper - Best of Both Worlds

## The Problem We Solved

You were right - we need BOTH approaches:
- ‚úÖ **Web scraping** = Fast, free, but some pages aren't structured consistently
- ‚úÖ **PDF extraction** = Reliable, always works, but costs AI credits (~$0.10-0.15 per subject)

## The Solution: Hybrid Scraper

The `aqa_hybrid_scraper.py` intelligently combines both methods:

```
For each subject:
‚îú‚îÄ Step 1: Try WEB SCRAPING
‚îÇ   ‚îî‚îÄ Navigate to subject-content pages
‚îÇ   ‚îî‚îÄ Parse HTML for topics
‚îÇ   ‚îî‚îÄ Extract hierarchical structure
‚îÇ   ‚îî‚îÄ Cost: $0 (free!)
‚îÇ   ‚îî‚îÄ Time: ~30 seconds
‚îÇ   
‚îú‚îÄ If web scraping succeeds:
‚îÇ   ‚îî‚îÄ ‚úì Upload to Supabase
‚îÇ   ‚îî‚îÄ ‚úì Mark as complete
‚îÇ   ‚îî‚îÄ ‚úì Move to next subject
‚îÇ   
‚îú‚îÄ If web scraping fails:
‚îÇ   ‚îî‚îÄ Step 2: FALLBACK to PDF EXTRACTION
‚îÇ       ‚îî‚îÄ Find PDF on specification page
‚îÇ       ‚îî‚îÄ Download PDF
‚îÇ       ‚îî‚îÄ Extract with AI (Claude)
‚îÇ       ‚îî‚îÄ Cost: ~$0.10-0.15
‚îÇ       ‚îî‚îÄ Time: ~2-3 minutes
‚îÇ       ‚îî‚îÄ ‚úì Upload to Supabase
‚îÇ       ‚îî‚îÄ ‚úì Mark as complete
```

## URL Patterns (Your Documentation)

### 1. Specification Page
```
https://www.aqa.org.uk/subjects/{subject}/{qual}/{subject}-{code}/specification
```
**Example:**
- Accounting A-Level: https://www.aqa.org.uk/subjects/accounting/a-level/accounting-7127/specification
- Economics A-Level: https://www.aqa.org.uk/subjects/economics/a-level/economics-7136/specification

**PDF is ALWAYS on this page!**

### 2. Subject Content Page
```
https://www.aqa.org.uk/subjects/{subject}/{qual}/{subject}-{code}/specification/subject-content
```
**Example:**
- Geography: https://www.aqa.org.uk/subjects/geography/a-level/geography-7037/specification/subject-content

**This page has numbered sections (3.1, 3.2) or option codes (1A, 1B)**

### 3. Individual Topic Pages
```
https://www.aqa.org.uk/subjects/{subject}/{qual}/{subject}-{code}/specification/subject-content/{topic-slug}
```
**Example:**
- Geography Physical: https://www.aqa.org.uk/subjects/geography/a-level/geography-7037/specification/subject-content/physical-geography

## How The Hybrid Scraper Works

### Web Scraping (Primary Method)

Your existing `aqa_web_scraper.py`:
1. Navigates to subject-content page
2. Detects pattern:
   - **Numbered sections**: "3.1 Financial Statements", "3.2 Cost Accounting"
   - **Option codes**: "1A Crusades", "1B Spain", "2A Stuart Britain"
3. Scrapes each content page
4. Extracts:
   - Topic code & title
   - Key questions
   - Study areas (h3 headings)
   - Sections (h4 headings)
   - Content points (bullet lists)
   - Periods (e.g., "1469-1598")

**Works great for:** Geography, Economics, Biology, Chemistry, Physics, etc.

**May fail for:** Subjects with inconsistent HTML structure

### PDF Extraction (Backup Method)

When web fails:
1. Navigate to specification page
2. Find PDF link (looks for `cdn.sanity.io` or `.pdf` links)
3. Download PDF
4. Use AI (Claude) to extract:
   - Specification metadata
   - Component structure (with selection rules!)
   - Selection constraints (geographic diversity, prohibited combos)
   - Topic options with codes
   - Subject vocabulary

**Always works** because PDF format is consistent

**Costs:** ~$0.10-0.15 per subject (Claude API)

## Cost Estimation

### Best Case (All subjects work with web scraping)
- **Cost:** $0
- **Time:** 74 subjects √ó 30 seconds = ~40 minutes

### Realistic Case (60 web, 14 PDF)
- **Web:** 60 subjects √ó $0 = $0
- **PDF:** 14 subjects √ó $0.12 = $1.68
- **Total:** ~$1.70
- **Time:** ~1.5 hours

### Worst Case (All subjects need PDF)
- **PDF:** 74 subjects √ó $0.12 = $8.88
- **Time:** 74 subjects √ó 2.5 minutes = ~3 hours

**Expected actual cost:** $2-5 for all 74 subjects

## What Gets Uploaded to Supabase

### From Web Scraping:
```sql
curriculum_topics:
- topic_code: "3.1" or "1A"
- topic_name: "Financial Statements"
- topic_level: 0 (main), 1 (study area)
- description: Full title
- key_themes: ["theme1", "theme2"]
- chronological_period: "1469-1598"
```

### From PDF Extraction:
```sql
specification_metadata:
- exam_board, subject, qualification
- total_guided_learning_hours
- assessment_overview

spec_components:
- component_code: "C1", "C2"
- selection_type: "choose_one", "required_all"
- count_required: 1
- total_available: 11

selection_constraints:
- constraint_type: "geographic_diversity"
- constraint_rule: {"must_include": ["British", "non-British"]}

curriculum_topics:
- topic_code: "1B"
- topic_name: "Spain in the Age of Discovery, 1469-1598"
- geographical_region: "European"
- chronological_period: "1469-1598"
- key_themes: JSON array
```

## Running The Hybrid Scraper

### Test Mode (3 subjects)
```bash
cd "C:\Users\tonyd\OneDrive - 4Sight Education Ltd\Apps\flash-curriculum-pipeline"
python batch_processor.py --test
```

### Full Run (all 74 subjects)
```bash
python batch_processor.py
```

### What You'll See In Logs:
```
[1/74] Processing: Accounting (A-Level)
Step 1: Attempting web scraping...
‚úì Web scraping SUCCESS - Found 18 content items
SUCCESS: Accounting_A-Level (method: web)

[2/74] Processing: Drama (GCSE)  
Step 1: Attempting web scraping...
‚úó Web scraping returned no content - will try PDF
Step 2: Falling back to PDF extraction...
‚úì Found PDF: https://cdn.sanity.io/files/.../drama.pdf
‚úì Downloaded PDF
üìä Extracting with AI (this costs ~$0.10-0.15)...
‚úì PDF extraction SUCCESS
SUCCESS: Drama_GCSE (method: pdf)
```

## Final Report

After processing, you get an HTML report showing:
- ‚úÖ **Completed**: Subject list + method used (web/pdf)
- ‚ö†Ô∏è **Partial**: Had issues but got some data
- ‚ùå **Failed**: Both methods failed (rare!)

## Why This is Better

### Old Approach (PDF only):
- ‚ùå Costs: $8-12 for all subjects
- ‚ùå Time: 2-4 hours
- ‚úÖ Always works

### Old Approach (Web only):
- ‚úÖ Cost: $0
- ‚úÖ Fast: 40 minutes
- ‚ùå Fails on some subjects
- ‚ùå No component rules/constraints

### NEW Hybrid Approach:
- ‚úÖ Cost: $2-5 for all subjects
- ‚úÖ Time: 1-2 hours
- ‚úÖ Always gets data (web or PDF)
- ‚úÖ Gets component rules when available
- ‚úÖ Smart fallback
- ‚úÖ Logs which method worked

## For Your App

The hybrid scraper gives you:

1. **Accurate topic lists** (from web or PDF)
2. **Component structure** (when available from PDF)
3. **Selection rules** (geographic diversity, etc.)
4. **Hierarchical data** (Level 0, Level 1, Level 2)
5. **Chronological periods** (for History, etc.)
6. **Key themes** (for better flashcard generation)

**Everything your app needs to show users accurate, constraint-aware topic selection!**

## Ready to Run?

```bash
# Test with 3 subjects first
python batch_processor.py --test

# If that works, run all 74
python batch_processor.py
```

The hybrid scraper will automatically:
- ‚úÖ Try web first
- ‚úÖ Fall back to PDF if needed
- ‚úÖ Upload to Supabase
- ‚úÖ Log which method worked
- ‚úÖ Generate report

**No more manual intervention needed!** üöÄ
