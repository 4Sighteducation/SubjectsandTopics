# FLASH Curriculum Pipeline - Quick Start Guide

## ğŸš€ What This System Does

Automatically scrapes curriculum data from exam boards (AQA, Cambridge, IB, etc.) and uploads to Supabase for the FLASH app.

**What it scrapes:**
- âœ… Subject specifications and metadata
- âœ… Component structure (what students must study)
- âœ… Selection constraints (rules for choosing topics)
- âœ… Topic hierarchies (options â†’ study areas â†’ content points)
- âœ… Subject vocabulary
- ğŸ”„ Past papers, mark schemes, examiner reports (coming soon)

## ğŸ“‹ Prerequisites

1. **Python 3.8+** installed
2. **Environment variables** set in `.env`:
   ```
   SUPABASE_URL=your_supabase_url
   SUPABASE_SERVICE_KEY=your_service_key
   ANTHROPIC_API_KEY=your_claude_api_key
   ```
3. **Dependencies** installed:
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ¯ Quick Start (3 Steps)

### Step 1: Check What Data You Already Have

**Windows:**
```bash
RUN-CHECK-DATA.bat
```

**Command line:**
```bash
python check_existing_data.py
```

**Output:** Opens HTML report showing:
- How many subjects/topics already in database
- Which exam boards have data
- What's missing
- Recommendations for next steps

### Step 2: Test the Batch Processor (3 subjects only)

**Windows:**
```bash
RUN-BATCH-AQA.bat
# Choose option 1 (TEST MODE)
```

**Command line:**
```bash
python batch_processor.py --test
```

**Output:** Processes 3 subjects to verify everything works.

### Step 3: Run Full Batch (all 74 AQA subjects)

**Windows:**
```bash
RUN-BATCH-AQA.bat
# Choose option 2 (FULL RUN)
```

**Command line:**
```bash
python batch_processor.py
```

**Duration:** 2-4 hours  
**Output:** HTML report with success/failure for each subject

## ğŸ“ File Structure

```
flash-curriculum-pipeline/
â”œâ”€â”€ batch_processor.py           # Batch process all AQA subjects
â”œâ”€â”€ check_existing_data.py       # Audit current database
â”œâ”€â”€ RUN-BATCH-AQA.bat           # Easy batch runner
â”œâ”€â”€ RUN-CHECK-DATA.bat          # Easy audit runner
â”‚
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ uk/
â”‚   â”‚   â”œâ”€â”€ aqa_scraper_enhanced.py      # AQA scraper
â”‚   â”‚   â”œâ”€â”€ ocr_scraper.py               # OCR scraper
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ international/
â”‚       â”œâ”€â”€ cambridge_scraper.py          # Cambridge IGCSE/A-Level
â”‚       â””â”€â”€ ib_scraper.py (coming)        # IB scraper
â”‚
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ supabase_client.py               # Upload to Supabase
â”‚   â””â”€â”€ migrations/                      # Database schema
â”‚       â”œâ”€â”€ 001_specification_metadata_tables.sql
â”‚       â”œâ”€â”€ 002_assessment_resources_tables.sql
â”‚       â””â”€â”€ 003_add_scraping_markers.sql
â”‚
â”œâ”€â”€ extractors/
â”‚   â””â”€â”€ specification_extractor.py       # AI extraction logic
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ aqa_subjects.yaml                # 74 AQA subjects
â”‚
â””â”€â”€ data/
    â”œâ”€â”€ raw/                             # Downloaded PDFs
    â”œâ”€â”€ processed/                       # Extracted JSON
    â”œâ”€â”€ logs/                            # Execution logs
    â”œâ”€â”€ state/                           # Resume state files
    â””â”€â”€ reports/                         # HTML reports
```

## ğŸ› ï¸ Common Commands

### Check Data Status
```bash
python check_existing_data.py
```

### Process Single Subject
```bash
# AQA
python -m scrapers.uk.aqa_scraper_enhanced --subject "History" --exam-type "A-Level"

# Cambridge
python -m scrapers.international.cambridge_scraper --subject "Mathematics" --qual "IGCSE"
```

### List Available Subjects
```bash
python -m scrapers.international.cambridge_scraper --list
```

### Process Without Uploading (Testing)
```bash
python batch_processor.py --test --no-upload
```

## ğŸ“Š Understanding the Output

### Batch Processor Report

Shows for each subject:
- âœ… **Completed:** Successfully scraped and uploaded
- âš ï¸ **Partial:** Some data extracted but had issues
- âŒ **Failed:** Could not process

### Data Audit Report

Shows:
- **Core Tables:** exam_boards, subjects, topics counts
- **Specification Tables:** metadata, components, constraints
- **Assessment Tables:** past papers, mark schemes, reports
- **Recommendations:** What to do next

## ğŸ› Troubleshooting

### "Missing environment variables"
- Check `.env` file exists
- Verify SUPABASE_URL, SUPABASE_SERVICE_KEY, ANTHROPIC_API_KEY are set

### "PDF download failed"
- AQA may have changed their website structure
- Check manual download from AQA website
- Update URL in `aqa_scraper_enhanced.py`

### "AI extraction failed"
- Check ANTHROPIC_API_KEY is valid
- Check API rate limits not exceeded
- Check PDF is not corrupted

### Batch processor stopped mid-run
- No problem! State is saved automatically
- Just run again - it will resume from where it stopped

## ğŸ“ˆ What's Next?

After running batch processor:

1. **Check the report** - review success/failures
2. **Verify in Supabase** - check data uploaded correctly
3. **International scrapers** - add Cambridge, IB
4. **Assessment resources** - add past papers scraper
5. **App integration** - implement pathway UI

## ğŸ”— Key Documents

- **COMPLETE-IMPLEMENTATION-PLAN.md** - Full strategy (4-5 week plan)
- **docs/COMPLETE-DATA-STRATEGY.md** - Why we need assessment resources
- **docs/TERMINOLOGY-AND-STRUCTURE-PLAN.md** - Database structure explained

## âš¡ Quick Reference

| Task | Command | Time |
|------|---------|------|
| Check data | `python check_existing_data.py` | 1 min |
| Test (3 subjects) | `python batch_processor.py --test` | 10 min |
| Full AQA (74 subjects) | `python batch_processor.py` | 2-4 hours |
| Single subject | `python -m scrapers.uk.aqa_scraper_enhanced --subject "X" --exam-type "Y"` | 3-5 min |
| Cambridge subject | `python -m scrapers.international.cambridge_scraper --subject "X" --qual "Y"` | 3-5 min |

## ğŸ’° API Costs

- **Per subject:** ~$0.10-0.15 (AI extraction)
- **74 AQA subjects:** ~$7-12
- **30 Cambridge subjects:** ~$3-5
- **Assessment resources (later):** ~$200-300

## ğŸ“ Getting Help

1. Check log files in `data/logs/`
2. Check state files in `data/state/`
3. Review audit report
4. Re-run in test mode to isolate issues

---

**Ready to start?**

```bash
# Step 1: See what you have
python check_existing_data.py

# Step 2: Test with 3 subjects
python batch_processor.py --test

# Step 3: Run full batch
python batch_processor.py
```

Good luck! ğŸš€
